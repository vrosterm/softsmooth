import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, TensorDataset
import os

# Load MNIST data
mnist_train = datasets.MNIST("C:/Users/walke/data", train=True, download=True, transform=transforms.ToTensor())
mnist_test = datasets.MNIST("C:/Users/walke/data", train=False, download=True, transform=transforms.ToTensor())
train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True)
test_loader = DataLoader(mnist_test, batch_size=100, shuffle=False)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
torch.manual_seed(0)

class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.shape[0], -1)

# Define the model
model_cnn = nn.Sequential(
    nn.Conv2d(1, 32, 3, padding=1),
    nn.ReLU(),
    nn.Conv2d(32, 32, 3, padding=1, stride=2),
    nn.ReLU(),
    nn.Conv2d(32, 64, 3, padding=1),
    nn.ReLU(),
    nn.Conv2d(64, 64, 3, padding=1, stride=2),
    nn.ReLU(),
    Flatten(),
    nn.Linear(7*7*64, 100),
    nn.ReLU(),
    nn.Linear(100, 10)
).to(device)

# Training and testing functions
def epoch(loader, model, opt=None):
    total_loss, total_err = 0., 0.
    for X, y in loader:
        X, y = X.to(device), y.to(device)
        yp = model(X)
        loss = nn.CrossEntropyLoss()(yp, y)
        if opt:
            opt.zero_grad()
            loss.backward()
            opt.step()
        total_err += (yp.max(dim=1)[1] != y).sum().item()
        total_loss += loss.item() * X.shape[0]
    return total_err / len(loader.dataset), total_loss / len(loader.dataset)

# Initialize optimizer and learning rate scheduler
opt = optim.SGD(model_cnn.parameters(), lr=1e-1)
scheduler = optim.lr_scheduler.StepLR(opt, step_size=5, gamma=0.1)

# Train the model
for epoch_num in range(10):  # Increase the number of epochs to allow the scheduler to take effect
    train_err, train_loss = epoch(train_loader, model_cnn, opt)
    test_err, test_loss = epoch(test_loader, model_cnn)
    scheduler.step()
    print(f"Epoch {epoch_num+1}: Train Accuracy: {100 - 100*train_err:.2f}%, Test Accuracy: {100 - 100*test_err:.2f}%")

# Save the trained model
torch.save(model_cnn.state_dict(), "model_cnn.pt")
print("Model saved.")
